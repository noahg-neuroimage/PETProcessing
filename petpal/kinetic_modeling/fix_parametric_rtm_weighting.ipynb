{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "from typing import Tuple, Callable, Union\n",
    "import nibabel\n",
    "import numpy as np\n",
    "import numba\n",
    "\n",
    "from petpal.kinetic_modeling.fit_tac_with_rtms import (\n",
    "                                                       get_rtm_method,\n",
    "                                                       get_rtm_output_size,\n",
    "                                                       get_rtm_kwargs)\n",
    "from petpal.utils.time_activity_curve import TimeActivityCurveFromFile\n",
    "from petpal.utils.image_io import safe_load_4dpet_nifti\n",
    "from petpal.kinetic_modeling import graphical_analysis\n",
    "from petpal.kinetic_modeling.reference_tissue_models import weight_tac_decay, weight_tac_simple\n",
    "from petpal.input_function.blood_input import read_plasma_glucose_concentration\n",
    "from petpal.utils.image_io import safe_load_tac, safe_copy_meta, validate_two_images_same_dimensions, load_metadata_for_nifti_with_same_filename, get_half_life_from_meta, safe_load_meta, get_half_life_from_nifti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rtm2_to_all_voxels(tac_times_in_minutes: np.ndarray,\n",
    "                             tgt_image: np.ndarray,\n",
    "                             ref_tac_vals: np.ndarray,\n",
    "                             mask_img: np.ndarray,\n",
    "                             method: str = 'srtm2',\n",
    "                             **analysis_kwargs) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates parametric images for 4D-PET data using the SRTM2 reference tissue method.\n",
    "\n",
    "    Args:\n",
    "        tac_times_in_minutes (np.ndarray): A 1D array representing the reference TAC and PET frame\n",
    "            times in minutes.\n",
    "        tgt_image (np.ndarray): A 4D array representing the 3D PET image over time.\n",
    "            The shape of this array should be (x, y, z, time).\n",
    "        ref_tac_vals (np.ndarray): A 1D array representing the reference TAC values. This array\n",
    "            should be of the same length as `tac_times_in_minutes`.\n",
    "        mask_img (np.ndarray): A 3D array representing the brain mask for `tgt_image`, where brain\n",
    "            regions are labelled 1 and non-brain regions are labelled 0. This is made necessary in\n",
    "            order to save time during computation. \n",
    "\n",
    "    Returns:\n",
    "        params_img (np.ndarray): A 4D array with RTM parameter fit results based on the supplied\n",
    "            method.\n",
    "    \"\"\"\n",
    "    use_bounds = None\n",
    "    if \"bounds\" in analysis_kwargs:\n",
    "        use_bounds = True\n",
    "    analysis_func = get_rtm_method(method=method,bounds=use_bounds)\n",
    "    img_dims = tgt_image.shape\n",
    "    output_shape = get_rtm_output_size(method=method)\n",
    "    params_img = np.zeros((img_dims[0], img_dims[1], img_dims[2], output_shape), float)\n",
    "\n",
    "    for i in range(0, img_dims[0], 1):\n",
    "        for j in range(0, img_dims[1], 1):\n",
    "            for k in range(0, img_dims[2], 1):\n",
    "                if mask_img[i,j,k]>0.5:\n",
    "                    analysis_vals = analysis_func(tac_times_in_minutes=tac_times_in_minutes,\n",
    "                                                  ref_tac_vals=ref_tac_vals,\n",
    "                                                  tgt_tac_vals=tgt_image[i, j, k, :],\n",
    "                                                  **analysis_kwargs)\n",
    "                    params_img[i,j,k] = analysis_vals[0]\n",
    "\n",
    "    return params_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rtm2_to_all_voxels_scan_timing(\n",
    "        tac_times_in_minutes: np.ndarray,\n",
    "                             tgt_image: np.ndarray,\n",
    "                             ref_tac_vals: np.ndarray,\n",
    "                             mask_img: np.ndarray,\n",
    "                             method: str = 'srtm2',\n",
    "                             **analysis_kwargs) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates parametric images for 4D-PET data using the SRTM2 reference tissue method.\n",
    "\n",
    "    Args:\n",
    "        tac_times_in_minutes (np.ndarray): A 1D array representing the reference TAC and PET frame\n",
    "            times in minutes.\n",
    "        tgt_image (np.ndarray): A 4D array representing the 3D PET image over time.\n",
    "            The shape of this array should be (x, y, z, time).\n",
    "        ref_tac_vals (np.ndarray): A 1D array representing the reference TAC values. This array\n",
    "            should be of the same length as `tac_times_in_minutes`.\n",
    "        mask_img (np.ndarray): A 3D array representing the brain mask for `tgt_image`, where brain\n",
    "            regions are labelled 1 and non-brain regions are labelled 0. This is made necessary in\n",
    "            order to save time during computation. \n",
    "\n",
    "    Returns:\n",
    "        params_img (np.ndarray): A 4D array with RTM parameter fit results based on the supplied\n",
    "            method.\n",
    "    \"\"\"\n",
    "    bounds = None\n",
    "    if \"bounds\" in analysis_kwargs:\n",
    "        bounds = True\n",
    "    analysis_func = get_rtm_method(method=method,bounds=bounds)\n",
    "    img_dims = tgt_image.shape\n",
    "    output_shape = get_rtm_output_size(method=method)\n",
    "    params_img = np.zeros((img_dims[0], img_dims[1], img_dims[2], output_shape), float)\n",
    "\n",
    "    for i in range(0, img_dims[0], 1):\n",
    "        for j in range(0, img_dims[1], 1):\n",
    "            for k in range(0, img_dims[2], 1):\n",
    "                if mask_img[i,j,k]>0.5:\n",
    "                    analysis_vals = analysis_func(tac_times_in_minutes=tac_times_in_minutes,\n",
    "                                                  ref_tac_vals=ref_tac_vals,\n",
    "                                                  tgt_tac_vals=tgt_image[i, j, k, :],\n",
    "                                                  **analysis_kwargs)\n",
    "                    params_img[i,j,k] = analysis_vals[0]\n",
    "\n",
    "    return params_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rtm2_to_all_voxels_weight_simple(scan_timing: ScanTimingInfo,\n",
    "                                           tgt_image: np.ndarray,\n",
    "                                           ref_tac_vals: np.ndarray,\n",
    "                                           mask_img: np.ndarray,\n",
    "                                           method: str = 'srtm2',\n",
    "                                           **analysis_kwargs) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates parametric images for 4D-PET data using the SRTM2 reference tissue method.\n",
    "\n",
    "    Args:\n",
    "        tac_times_in_minutes (np.ndarray): A 1D array representing the reference TAC and PET frame\n",
    "            times in minutes.\n",
    "        tgt_image (np.ndarray): A 4D array representing the 3D PET image over time.\n",
    "            The shape of this array should be (x, y, z, time).\n",
    "        ref_tac_vals (np.ndarray): A 1D array representing the reference TAC values. This array\n",
    "            should be of the same length as `tac_times_in_minutes`.\n",
    "        mask_img (np.ndarray): A 3D array representing the brain mask for `tgt_image`, where brain\n",
    "            regions are labelled 1 and non-brain regions are labelled 0. This is made necessary in\n",
    "            order to save time during computation. \n",
    "\n",
    "    Returns:\n",
    "        params_img (np.ndarray): A 4D array with RTM parameter fit results based on the supplied\n",
    "            method.\n",
    "    \"\"\"\n",
    "    bounds = None\n",
    "    if \"bounds\" in analysis_kwargs:\n",
    "        bounds = True\n",
    "    analysis_func = get_rtm_method(method=method,bounds=bounds)\n",
    "    img_dims = tgt_image.shape\n",
    "    output_shape = get_rtm_output_size(method=method)\n",
    "    params_img = np.zeros((img_dims[0], img_dims[1], img_dims[2], output_shape), float)\n",
    "\n",
    "    for i in range(0, img_dims[0], 1):\n",
    "        for j in range(0, img_dims[1], 1):\n",
    "            for k in range(0, img_dims[2], 1):\n",
    "                if mask_img[i,j,k]>0.5:\n",
    "                    tac_vals = tgt_image[i, j, k, :]\n",
    "                    voxel_uncertainties = weight_tac_simple(tac_durations_in_minutes=scan_timing.duration,\n",
    "                                                            tac_vals=tac_vals)\n",
    "                    analysis_vals = analysis_func(tac_times_in_minutes=scan_timing.center,\n",
    "                                                  ref_tac_vals=ref_tac_vals,\n",
    "                                                  tgt_tac_vals=tac_vals,\n",
    "                                                  uncertainties=voxel_uncertainties,\n",
    "                                                  **analysis_kwargs)\n",
    "                    params_img[i,j,k] = analysis_vals[0]\n",
    "\n",
    "    return params_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rtm2_to_all_voxels_weight_decay(scan_timing: ScanTimingInfo,\n",
    "                                           tgt_image: np.ndarray,\n",
    "                                           ref_tac_vals: np.ndarray,\n",
    "                                           mask_img: np.ndarray,\n",
    "                                           half_life: float, \n",
    "                                           method: str = 'srtm2',\n",
    "                                           **analysis_kwargs) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates parametric images for 4D-PET data using the SRTM2 reference tissue method.\n",
    "\n",
    "    Args:\n",
    "        tac_times_in_minutes (np.ndarray): A 1D array representing the reference TAC and PET frame\n",
    "            times in minutes.\n",
    "        tgt_image (np.ndarray): A 4D array representing the 3D PET image over time.\n",
    "            The shape of this array should be (x, y, z, time).\n",
    "        ref_tac_vals (np.ndarray): A 1D array representing the reference TAC values. This array\n",
    "            should be of the same length as `tac_times_in_minutes`.\n",
    "        mask_img (np.ndarray): A 3D array representing the brain mask for `tgt_image`, where brain\n",
    "            regions are labelled 1 and non-brain regions are labelled 0. This is made necessary in\n",
    "            order to save time during computation. \n",
    "\n",
    "    Returns:\n",
    "        params_img (np.ndarray): A 4D array with RTM parameter fit results based on the supplied\n",
    "            method.\n",
    "    \"\"\"\n",
    "    bounds = None\n",
    "    if \"bounds\" in analysis_kwargs:\n",
    "        bounds = True\n",
    "    analysis_func = get_rtm_method(method=method,bounds=bounds)\n",
    "    img_dims = tgt_image.shape\n",
    "    output_shape = get_rtm_output_size(method=method)\n",
    "    params_img = np.zeros((img_dims[0], img_dims[1], img_dims[2], output_shape), float)\n",
    "\n",
    "    for i in range(0, img_dims[0], 1):\n",
    "        for j in range(0, img_dims[1], 1):\n",
    "            for k in range(0, img_dims[2], 1):\n",
    "                if mask_img[i,j,k]>0.5:\n",
    "                    tac_vals = tgt_image[i, j, k, :]\n",
    "                    voxel_uncertainties = weight_tac_decay(tac_durations_in_minutes=scan_timing.duration,\n",
    "                                                           tac_vals=tac_vals,\n",
    "                                                           half_life_in_minutes=half_life)\n",
    "                    analysis_vals = analysis_func(tac_times_in_minutes=scan_timing.center,\n",
    "                                                  ref_tac_vals=ref_tac_vals,\n",
    "                                                  tgt_tac_vals=tac_vals,\n",
    "                                                  uncertainties=voxel_uncertainties,\n",
    "                                                  **analysis_kwargs)\n",
    "                    params_img[i,j,k] = analysis_vals[0]\n",
    "\n",
    "    return params_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ScanTimingInfo:\n",
    "    \"\"\"\n",
    "    A data structure to represent and streamline access to timing information for image scans.\n",
    "\n",
    "    This class encapsulates details about a scan's timing, including:\n",
    "    - Start and end times of each scan frame.\n",
    "    - Duration and center times of the frames.\n",
    "    - Decay values (if applicable).\n",
    "\n",
    "    Additionally, the class provides properties for easy conversion of timing values to minutes\n",
    "    if the times are given in seconds and exceed a threshold (assumed to be 200.0 seconds).\n",
    "\n",
    "    Attributes:\n",
    "        duration (np.ndarray[float]): Array of frame durations.\n",
    "        end (np.ndarray[float]): Array of frame end times.\n",
    "        start (np.ndarray[float]): Array of frame start times.\n",
    "        center (np.ndarray[float]): Array of frame center times (midpoints).\n",
    "        decay (np.ndarray[float]): Array of decay coefficients for the scan frames.\n",
    "\n",
    "    Properties:\n",
    "        duration_in_mins (np.ndarray[float]):\n",
    "            Returns the frame durations converted to minutes if `end` is >= 200.0 seconds.\n",
    "            Otherwise, returns the original durations.\n",
    "\n",
    "        end_in_mins (np.ndarray[float]):\n",
    "            Returns the frame end times converted to minutes if `end` is >= 200.0 seconds.\n",
    "            Otherwise, returns the original end times.\n",
    "\n",
    "        start_in_mins (np.ndarray[float]):\n",
    "            Returns the frame start times converted to minutes if `end` is >= 200.0 seconds.\n",
    "            Otherwise, returns the original start times.\n",
    "\n",
    "        center_in_mins (np.ndarray[float]):\n",
    "            Returns the frame center times converted to minutes if `end` is >= 200.0 seconds.\n",
    "            Otherwise, returns the original center times.\n",
    "\n",
    "    Examples:\n",
    "\n",
    "        .. code-block:: python\n",
    "\n",
    "            import numpy as np\n",
    "            from petpal.utils.image_io import ScanTimingInfo, get_frame_timing_info_for_nifti\n",
    "\n",
    "            # Explicitly setting the attributes\n",
    "            ## Define scan timing information\n",
    "            duration = np.array([60.0, 120.0, 180.0])  # seconds\n",
    "            start = np.array([0.0, 60.0, 180.0])\n",
    "            end = np.array([60.0, 180.0, 360.0])\n",
    "            center = (start + end) / 2.0  # Calculate the midpoints\n",
    "            decay = np.array([1.0, 0.9, 0.8])  # Example decay values\n",
    "\n",
    "            ## Create an instance of ScanTimingInfo\n",
    "            scan_timing_info = ScanTimingInfo(duration=duration, end=end, start=start, center=center, decay=decay)\n",
    "\n",
    "            ## Access original timing information\n",
    "            print(scan_timing_info.duration)  # [ 60. 120. 180.]\n",
    "            print(scan_timing_info.center)    # [30.  120. 270.]\n",
    "\n",
    "            ## Access timing as minutes (when times exceed 200.0 seconds)\n",
    "            print(scan_timing_info.duration_in_mins)  # [ 60. 120. 180.] (Unchanged)\n",
    "            print(scan_timing_info.center_in_mins)    # [30. 120. 270.] (Unchanged)\n",
    "\n",
    "            ## Example when `end` is greater than 200.0:\n",
    "            scan_timing_info.end = np.array([300.0, 400.0, 500.0])  # Update end times\n",
    "            print(scan_timing_info.end_in_mins)  # [5. 6.66666667 8.33333333] (Converted to minutes)\n",
    "            print(scan_timing_info.start_in_mins)  # [0. 1. 3.] (Converted to minutes)\n",
    "\n",
    "            # Getting the object directly from a nifty image file (assuming the metadata shares the name)\n",
    "            scan_timing_info = get_frame_timing_info_for_nifti(\"/path/to/image.nii.gz\")\n",
    "\n",
    "    \"\"\"\n",
    "    duration: np.ndarray[float]\n",
    "    end: np.ndarray[float]\n",
    "    start: np.ndarray[float]\n",
    "    center: np.ndarray[float]\n",
    "    decay: np.ndarray[float]\n",
    "\n",
    "    @property\n",
    "    def duration_in_mins(self) -> np.ndarray[float]:\n",
    "        if self.end[-1] >= 200.0:\n",
    "            return self.duration / 60.0\n",
    "        else:\n",
    "            return self.duration\n",
    "\n",
    "    @property\n",
    "    def end_in_mins(self) -> np.ndarray[float]:\n",
    "        if self.end[-1] >= 200.0:\n",
    "            return self.end / 60.0\n",
    "        else:\n",
    "            return self.end\n",
    "\n",
    "    @property\n",
    "    def start_in_mins(self) -> np.ndarray[float]:\n",
    "        if self.end[-1] >= 200.0:\n",
    "            return self.start / 60.0\n",
    "        else:\n",
    "            return self.start\n",
    "\n",
    "    @property\n",
    "    def center_in_mins(self) -> np.ndarray[float]:\n",
    "        if self.end[-1] >= 200.0:\n",
    "            return self.center / 60.0\n",
    "        else:\n",
    "            return self.center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_timing_info_for_metadata(metadata_dict: dict) -> ScanTimingInfo:\n",
    "    r\"\"\"\n",
    "    Extracts frame timing information and decay factors from a json metadata.\n",
    "    Expects that the JSON metadata has ``FrameDuration`` and ``DecayFactor`` or\n",
    "    ``DecayCorrectionFactor`` keys.\n",
    "\n",
    "    .. important::\n",
    "        This function tries to infer `FrameTimesEnd` and `FrameTimesStart` from the frame durations\n",
    "        if those keys are not present in the metadata file. If the scan is broken, this might generate\n",
    "        incorrect results.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        metadata_dict (dict): The metadata dictionary, loaded into memory.\n",
    "\n",
    "    Returns:\n",
    "        :class:`ScanTimingInfo`: Frame timing information with the following elements:\n",
    "            - duration (np.ndarray): Frame durations in seconds.\n",
    "            - start (np.ndarray): Frame start times in seconds.\n",
    "            - end (np.ndarray): Frame end times in seconds.\n",
    "            - center (np.ndarray): Frame center times in seconds.\n",
    "            - decay (np.ndarray): Decay factors for each frame.\n",
    "    \"\"\"\n",
    "    frm_dur = np.asarray(metadata_dict['FrameDuration'], float)\n",
    "    try:\n",
    "        frm_ends = np.asarray(metadata_dict['FrameTimesEnd'], float)\n",
    "    except KeyError:\n",
    "        frm_ends = np.cumsum(frm_dur)\n",
    "    try:\n",
    "        frm_starts = np.asarray(metadata_dict['FrameTimesStart'], float)\n",
    "    except KeyError:\n",
    "        frm_starts = np.diff(frm_ends)\n",
    "    try:\n",
    "        decay = np.asarray(metadata_dict['DecayCorrectionFactor'], float)\n",
    "    except KeyError:\n",
    "        decay = np.asarray(metadata_dict['DecayFactor'], float)\n",
    "    try:\n",
    "        frm_centers = np.asarray(metadata_dict['FrameReferenceTime'], float)\n",
    "    except KeyError:\n",
    "        frm_centers = np.asarray(frm_starts + frm_dur / 2.0, float)\n",
    "\n",
    "    return ScanTimingInfo(duration=frm_dur, start=frm_starts, end=frm_ends, center=frm_centers, decay=decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_timing_info_for_nifti(image_path: str) -> ScanTimingInfo:\n",
    "    r\"\"\"\n",
    "    Extracts frame timing information and decay factors from a NIfTI image metadata.\n",
    "    Expects that the JSON metadata file has ``FrameDuration`` and ``DecayFactor`` or\n",
    "    ``DecayCorrectionFactor`` keys.\n",
    "\n",
    "    .. important::\n",
    "        This function tries to infer `FrameTimesEnd` and `FrameTimesStart` from the frame durations\n",
    "        if those keys are not present in the metadata file. If the scan is broken, this might generate\n",
    "        incorrect results.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the NIfTI image file.\n",
    "\n",
    "    Returns:\n",
    "        scan_timing (:class:`ScanTimingInfo`): Frame timing information with the following elements:\n",
    "            - duration (np.ndarray): Frame durations in seconds.\n",
    "            - start (np.ndarray): Frame start times in seconds.\n",
    "            - end (np.ndarray): Frame end times in seconds.\n",
    "            - center (np.ndarray): Frame center times in seconds.\n",
    "            - decay (np.ndarray): Decay factors for each frame.\n",
    "    \"\"\"\n",
    "    _meta_data = load_metadata_for_nifti_with_same_filename(image_path=image_path)\n",
    "    scan_timing = get_frame_timing_info_for_metadata(_meta_data)\n",
    "\n",
    "    return scan_timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReferenceTissueParametricImage:\n",
    "    \"\"\"\n",
    "    Class for generating parametric images of 4D-PET images using reference tissue model (RTM)\n",
    "    methods.\n",
    "\n",
    "    Example:\n",
    "        .. code-block:: python\n",
    "            \n",
    "            from petpal.kinetic_modeling import parametric_images\n",
    "            \n",
    "            rtm_parametric = ReferenceTissueParametricImage(reference_tac_path='/path/to/tac.tsv',\n",
    "                                                            pet_image_path='/path/to/pet.nii.gz',\n",
    "                                                            mask_image_path='/path/to/mask.nii.gz',\n",
    "                                                            output_directory='/path/to/output,\n",
    "                                                            output_filename_prefix='sub-001_mrtm2')\n",
    "            rtm_parametric.run_parametric_analysis(method='mrtm2',\n",
    "                                                   k2_prime=0.01,\n",
    "                                                   t_thresh_in_mins=30)\n",
    "            rtm_parametric.save_parametric_images()\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 reference_tac_path: str,\n",
    "                 pet_image_path: str,\n",
    "                 mask_image_path: str,\n",
    "                 output_directory: str,\n",
    "                 output_filename_prefix: str,\n",
    "                 method: str='mrtm2'):\n",
    "        \"\"\"\n",
    "        Initialize ReferenceTissueParametricImage with input values.\n",
    "\n",
    "        Args:\n",
    "            reference_tac_path (str): Path to the reference region TAC file.\n",
    "            pet_image_path (str): Path to the 4D PET image on which kinetic analysis is performed.\n",
    "            mask_image_path (str): Path to image that masks the brain in the same space as the PET\n",
    "                image.\n",
    "            output_directory (str): Path to folder where analysis is saved.\n",
    "            output_filename_prefix (str): Prefix for output files saved after analysis.\n",
    "            method (str): RTM method to run. Default 'mrtm2'.\n",
    "        \"\"\"\n",
    "        self.reference_tac = TimeActivityCurveFromFile(tac_path=reference_tac_path)\n",
    "        self.pet_image = safe_load_4dpet_nifti(pet_image_path)\n",
    "        self.mask_image = safe_load_4dpet_nifti(mask_image_path)\n",
    "        self.metadata = load_metadata_for_nifti_with_same_filename(pet_image_path)\n",
    "\n",
    "        validate_two_images_same_dimensions(self.pet_image,self.mask_image,check_4d=False)\n",
    "\n",
    "        self.output_directory = output_directory\n",
    "        self.output_filename_prefix = output_filename_prefix\n",
    "        self.method = method\n",
    "        self.analysis_props = self.init_analysis_props(method)\n",
    "        self.set_time_dependent_properties(image_path=pet_image_path)\n",
    "        self.set_analysis_kwargs()\n",
    "        self.fit_results = None, None\n",
    "\n",
    "\n",
    "    def set_time_dependent_properties(self, image_path: str):\n",
    "        \"Extract scan timing info and half life from the PET image metadata\"\n",
    "        self.half_life = get_half_life_from_nifti(image_path=image_path)\n",
    "        self.scan_timing = get_frame_timing_info_for_nifti(image_path=image_path)\n",
    "\n",
    "\n",
    "    def init_analysis_props(self, method: str) -> dict:\n",
    "        r\"\"\"\n",
    "        Initializes the analysis properties dict based on the specified RTM analysis method.\n",
    "\n",
    "        Args:\n",
    "            method (str): RTM analysis method. Must be one of 'srtm', 'frtm', 'mrtm-original',\n",
    "                'mrtm' or 'mrtm2'.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing method-specific property keys and default values.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If input `method` is not one of the supported RTM methods.\n",
    "        \"\"\"\n",
    "        common_props = {'MethodName': method.upper()}\n",
    "        if method.startswith(\"mrtm\"):\n",
    "            props = {\n",
    "                'BP': None,\n",
    "                'k2Prime': None,\n",
    "                'ThresholdTime': None,\n",
    "                'Bounds': None,\n",
    "                'StartFrameTime': None,\n",
    "                'EndFrameTime' : None,\n",
    "                'NumberOfPointsFit': None,\n",
    "                'RawFits': None,\n",
    "                **common_props\n",
    "                }\n",
    "        elif method.startswith(\"srtm\") or method.startswith(\"frtm\"):\n",
    "            props = {\n",
    "                'FitValues': None,\n",
    "                'FitStdErr': None,\n",
    "                **common_props\n",
    "                }\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid method! Must be either 'srtm', 'frtm', 'srtm2', 'frtm2', \"\n",
    "                             f\"'mrtm-original', 'mrtm' or 'mrtm2'. Got {method}.\")\n",
    "        return props\n",
    "\n",
    "\n",
    "    def set_analysis_props(self,\n",
    "                           props: dict,\n",
    "                           bounds: None | np.ndarray = None,\n",
    "                           k2_prime: float=None,\n",
    "                           t_thresh_in_mins: float=None,\n",
    "                           image_scale: float=1):\n",
    "        \"\"\"\n",
    "        Set kwargs used for running parametric analysis.\n",
    "\n",
    "        Args:\n",
    "            props (dict): Dictionary to be updated with analysis properties.\n",
    "            bounds (None | np.ndarray): Bounds used in RTM analysis, if any. Default None.\n",
    "            k2_prime (float): k2_prime used in RTM analysis, if any. Default None.\n",
    "            t_thresh_in_mins (float): Threshold time from which model is computed, if any. Default None.\n",
    "            image_scale (float): Scale factor by which image is multiplied before the model is run. Default 1.\n",
    "        \"\"\"\n",
    "        props['Bounds'] = bounds\n",
    "        props['k2Prime'] = k2_prime\n",
    "        props['ThresholdTime'] = t_thresh_in_mins\n",
    "        props['ImageScale'] = image_scale\n",
    "\n",
    "\n",
    "    def set_analysis_kwargs(self,\n",
    "                            bounds: None | np.ndarray = None,\n",
    "                            k2_prime: float=None,\n",
    "                            t_thresh_in_mins: float=None):\n",
    "        \"\"\"\n",
    "        Get kwargs used for running parametric analysis.\n",
    "\n",
    "        Args:\n",
    "\n",
    "        \"\"\"\n",
    "        rtm_method = get_rtm_method(self.method)\n",
    "        self.analysis_kwargs = get_rtm_kwargs(method=rtm_method,\n",
    "                                              bounds=bounds,\n",
    "                                              k2_prime=k2_prime,\n",
    "                                              t_thresh_in_mins=t_thresh_in_mins)\n",
    "\n",
    "\n",
    "    def get_rtm_analysis_func(self):\n",
    "        use_bounds = None\n",
    "        if \"bounds\" in self.analysis_kwargs:\n",
    "            use_bounds = True\n",
    "        analysis_func = get_rtm_method(method=self.method,bounds=use_bounds)\n",
    "        return analysis_func\n",
    "\n",
    "    @numba.njit()\n",
    "    def apply_rtm2_to_all_voxels_weight_decay(self,\n",
    "                                              tgt_image: np.ndarray,\n",
    "                                              ref_tac_vals: np.ndarray,\n",
    "                                              mask_img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generates parametric images for 4D-PET data using the SRTM2 reference tissue method.\n",
    "\n",
    "        Args:\n",
    "            tac_times_in_minutes (np.ndarray): A 1D array representing the reference TAC and PET frame\n",
    "                times in minutes.\n",
    "            tgt_image (np.ndarray): A 4D array representing the 3D PET image over time.\n",
    "                The shape of this array should be (x, y, z, time).\n",
    "            ref_tac_vals (np.ndarray): A 1D array representing the reference TAC values. This array\n",
    "                should be of the same length as `tac_times_in_minutes`.\n",
    "            mask_img (np.ndarray): A 3D array representing the brain mask for `tgt_image`, where brain\n",
    "                regions are labelled 1 and non-brain regions are labelled 0. This is made necessary in\n",
    "                order to save time during computation. \n",
    "\n",
    "        Returns:\n",
    "            params_img (np.ndarray): A 4D array with RTM parameter fit results based on the supplied\n",
    "                method.\n",
    "        \"\"\"\n",
    "        analysis_func = self.get_rtm_analysis_func()\n",
    "        img_dims = tgt_image.shape\n",
    "        output_shape = get_rtm_output_size(method=self.method)\n",
    "        params_img = np.zeros((img_dims[0], img_dims[1], img_dims[2], output_shape), float)\n",
    "\n",
    "        for i in range(0, img_dims[0], 1):\n",
    "            for j in range(0, img_dims[1], 1):\n",
    "                for k in range(0, img_dims[2], 1):\n",
    "                    if mask_img[i,j,k]>0.5:\n",
    "                        tac_vals = tgt_image[i, j, k, :]\n",
    "                        voxel_uncertainties = weight_tac_decay(tac_durations_in_minutes=self.scan_timing.duration,\n",
    "                                                               tac_vals=tac_vals,\n",
    "                                                               half_life_in_minutes=self.half_life)\n",
    "                        analysis_vals = analysis_func(tac_times_in_minutes=self.scan_timing.center,\n",
    "                                                      ref_tac_vals=ref_tac_vals,\n",
    "                                                      tgt_tac_vals=tac_vals,\n",
    "                                                      uncertainties=voxel_uncertainties,\n",
    "                                                      **self.analysis_kwargs)\n",
    "                        params_img[i,j,k] = analysis_vals[0]\n",
    "\n",
    "        return params_img\n",
    "\n",
    "\n",
    "    def run_parametric_analysis(self,\n",
    "                                image_scale: float=1):\n",
    "        \"\"\"\n",
    "        Run the analysis.\n",
    "\n",
    "        Args:\n",
    "            image_scale (float): Factor by which to scale PET data before running analysis.\n",
    "                This is intended to be used for unit conversion.\n",
    "        \n",
    "        Returns:\n",
    "            fit_results (np.ndarray, Tuple[np.ndarray, np.ndarray]): Kinetic parameters and\n",
    "                simulated data returned as arrays. \n",
    "        \"\"\"\n",
    "        pet_np = self.pet_image.get_fdata()\n",
    "        mask_np = self.mask_image.get_fdata()\n",
    "        ref_tac_vals = self.reference_tac.tac_vals\n",
    "\n",
    "        fit_results = self.apply_rtm2_to_all_voxels(tgt_image=pet_np * image_scale,\n",
    "                                                    ref_tac_vals=ref_tac_vals,\n",
    "                                                    mask_img=mask_np)\n",
    "        self.fit_results = fit_results\n",
    "\n",
    "\n",
    "    def save_parametric_images(self):\n",
    "        \"\"\"\n",
    "        Save parametric images.\n",
    "        \"\"\"\n",
    "        fit_image = self.fit_results\n",
    "        pet_image = self.pet_image\n",
    "        fit_nibabel = nibabel.nifti1.Nifti1Image(dataobj=fit_image,\n",
    "                                                 affine=pet_image.affine,\n",
    "                                                 header=pet_image.header)\n",
    "\n",
    "        try:\n",
    "            fit_image_path = os.path.join(self.output_directory,\n",
    "                                    f\"{self.output_filename_prefix}_desc-rtmfit_pet.nii.gz\")\n",
    "            nibabel.save(fit_nibabel,fit_image_path)\n",
    "        except IOError as exc:\n",
    "            print(\"An IOError occurred while attempting to write the NIfTI image files.\")\n",
    "            raise exc from None\n",
    "\n",
    "\n",
    "    def save_analysis_properties(self):\n",
    "        \"\"\"\n",
    "        Saves the analysis properties to a JSON file in the output directory.\n",
    "\n",
    "        This method involves saving a dictionary of analysis properties, which include file paths,\n",
    "        analysis method, start and end frame times, threshold time, number of points fitted, and \n",
    "        various properties like the maximum, minimum, mean, and variance of slopes and intercepts\n",
    "        found in the analysis. These analysis properties are written to a JSON file in the output\n",
    "        directory with the name following the pattern\n",
    "        `{output_filename_prefix}-analysis-props.json`.\n",
    "\n",
    "        Args:\n",
    "            None\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "\n",
    "        Raises:\n",
    "            IOError: An error occurred accessing the output_directory or while writing to the JSON\n",
    "            file.\n",
    "\n",
    "        See Also:\n",
    "            * :func:`save_analysis_properties`\n",
    "        \"\"\"\n",
    "        analysis_props_file = os.path.join(self.output_directory,\n",
    "                                           f\"{self.output_filename_prefix}_desc-\"\n",
    "                                           f\"{self.analysis_props['MethodName']}_props.json\")\n",
    "        with open(analysis_props_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(obj=self.analysis_props, fp=f, indent=4)\n",
    "\n",
    "\n",
    "    def __call__(self,\n",
    "                 bounds: np.ndarray=None,\n",
    "                 t_thresh_in_mins: float=None,\n",
    "                 k2_prime: float=None,\n",
    "                 image_scale: float=None):\n",
    "        self.run_parametric_analysis(bounds=bounds,\n",
    "                                     t_thresh_in_mins=t_thresh_in_mins,\n",
    "                                     k2_prime=k2_prime,\n",
    "                                     image_scale=image_scale)\n",
    "        self.set_analysis_props(props=self.analysis_props,\n",
    "                                bounds=bounds,\n",
    "                                k2_prime=k2_prime,\n",
    "                                t_thresh_in_mins=t_thresh_in_mins,\n",
    "                                image_scale=image_scale)\n",
    "        self.save_parametric_images()\n",
    "        self.save_analysis_properties()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/scratch1/PETPAL/VATDYS/derivatives/petpal_25Feb25/sub-PIB07018/ses-VYr12/pet/sub-PIB07018_ses-VYr12_space-atlas_pet.nii.gz\n"
     ]
    }
   ],
   "source": [
    "rtpi = ReferenceTissueParametricImage(\n",
    "    reference_tac_path='/export/scratch1/PETPAL/VATDYS/derivatives/petpal_25Feb25/sub-PIB07018/ses-VYr12/tacs_atlas/sub-PIB07018_ses-VYr12_seg-WMRef_tac.tsv',\n",
    "    pet_image_path='/export/scratch1/PETPAL/VATDYS/derivatives/petpal_25Feb25/sub-PIB07018/ses-VYr12/pet/sub-PIB07018_ses-VYr12_space-atlas_pet.nii.gz',\n",
    "    mask_image_path='/data/jsp/human2/AaronProjects/PRISMA_TRIO_PIB_NL/PRISMA_TRIO_PIB_NL_MNI152_0p9mm_brain_mask.nii.gz',\n",
    "    output_directory='/export/scratch1/PETPAL/VATDYS/derivatives/petpal_25Feb25/sub-PIB07018/ses-VYr12/km',\n",
    "    output_filename_prefix='sub-PIB07018_ses-VYr12_mrtm2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtpi."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PETPAL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
